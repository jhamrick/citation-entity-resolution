{
 "metadata": {
  "kernelspec": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "display_name": "IPython (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "name": "",
  "signature": "sha256:0f73ac8d9df3573883019c6b5e1fbc74afd35a199121d61e35fefcc5d3107d91"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Go through all the authors in `citations.h5` and bin them according to the first character of the last name. Save the bins into the same database, but under a new group, called `buckets`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import json\n",
      "import os\n",
      "import sys\n",
      "from unidecode import unidecode\n",
      "from IPython.display import clear_output"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# open the citations database for reading and access the group\n",
      "# holding all the citation information\n",
      "store = pd.HDFStore(\"citations.h5\", mode='r')\n",
      "doi_group = store.get_node('dois')\n",
      "\n",
      "# allocate our bins\n",
      "buckets = {}\n",
      "\n",
      "# walk through all the nodes in the database\n",
      "for df in doi_group._f_walknodes('Group'):\n",
      "    # skip groups that don't have a leaf (data) attached to them\n",
      "    if len(df._v_leaves) == 0:\n",
      "        continue\n",
      "\n",
      "    # get the full path in the database to the data\n",
      "    citation = df._v_pathname\n",
      "\n",
      "    # print progress\n",
      "    clear_output()\n",
      "    print(\"Binning authors in '{}'\".format(citation))\n",
      "    sys.stdout.flush()\n",
      "\n",
      "    # get the author information\n",
      "    data = store[citation]\n",
      "\n",
      "    # go through each author for the citation\n",
      "    for i, row in data.iterrows():\n",
      "        # skip authors that don't have a first or last name\n",
      "        if 'family' not in row or 'given' not in row:\n",
      "            continue\n",
      "        if not isinstance(row['family'], str):\n",
      "            continue\n",
      "\n",
      "        # get the first letter of the last name -- we need to use\n",
      "        # unidecode because we want to bin names together even if\n",
      "        # some of them have accents\n",
      "        letter = unidecode(row['family'][0]).lower()\n",
      "        if letter not in buckets:\n",
      "            buckets[letter] = []\n",
      "        buckets[letter].append(row)\n",
      "\n",
      "# close the database\n",
      "store.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Binning authors in '/dois/_10_1371/journal_pmed/_0/_0/_1/_0/_0/_0010066'\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# print out information about the size of the buckets\n",
      "for bucket in sorted(buckets.keys()):\n",
      "    print(\"{}: {}\".format(bucket, len(buckets[bucket])))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "3: 1\n",
        "a: 2364\n",
        "b: 4433\n",
        "c: 4827\n",
        "d: 2972\n",
        "e: 943\n",
        "f: 2144\n",
        "g: 3284\n",
        "h: 4230\n",
        "i: 628\n",
        "j: 1576\n",
        "k: 3773\n",
        "l: 5434\n",
        "m: 5051\n",
        "n: 1652\n",
        "o: 1128\n",
        "p: 3163\n",
        "q: 296\n",
        "r: 2644\n",
        "s: 6438\n",
        "t: 2647\n",
        "u: 282\n",
        "v: 1726\n",
        "w: 3617\n",
        "x: 715\n",
        "y: 1754\n",
        "z: 2465\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# open the database again to store the buckets\n",
      "store = pd.HDFStore('citations.h5', mode='a')\n",
      "\n",
      "for bucket in buckets:\n",
      "    # turn the bucket into a dataframe\n",
      "    df = pd.DataFrame(buckets[bucket])\\\n",
      "        .sort(['family', 'given'])\\\n",
      "        .reset_index(drop=True)\n",
      "\n",
      "    # save it into the database\n",
      "    store.put(\"buckets/_{}\".format(bucket), df)\n",
      "\n",
      "# close the database\n",
      "store.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/usr/lib/python3/dist-packages/pandas/io/pytables.py:2446: PerformanceWarning: \n",
        "your performance may suffer as PyTables will pickle object types that it cannot\n",
        "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['affiliation', 'doi', 'email', 'family', 'given']]\n",
        "\n",
        "  warnings.warn(ws, PerformanceWarning)\n"
       ]
      }
     ],
     "prompt_number": 5
    }
   ],
   "metadata": {}
  }
 ]
}